{"cells":[{"cell_type":"code","source":["!pip install keras_nlp"],"metadata":{"id":"sT_PSdaobpD2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","import tensorflow as tf\n","import keras_nlp\n","import numpy as np\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","np.random.seed(2)\n","tokenizer = AutoTokenizer.from_pretrained('t5-base', bos_token=\"<start>\")\n","\n","\n","class TransformerEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, embedding_dim, max_seq_len):\n","        super(TransformerEmbedding, self).__init__()\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.positional_encoding = keras_nlp.layers.SinePositionEncoding()\n","\n","    def call(self, sequences):\n","        embeddings = self.embedding(sequences)\n","        positional_encoding = self.positional_encoding(embeddings)\n","        outputs = embeddings + positional_encoding\n","        return outputs\n","\n","    def get_weights(self):\n","        return self.embedding.get_weights()\n","\n","    def set_weights(self, weights):\n","        self.embedding.set_weights(weights)\n","\n","\n","class FeedForward(tf.keras.layers.Layer):\n","    def __init__(self, dModel):\n","        super(FeedForward, self).__init__()\n","        self.l1 = tf.keras.layers.Dense(dModel * 4, activation='relu')\n","        self.l2 = tf.keras.layers.Dense(dModel)\n","\n","    def call(self, x, *args, **kwargs):\n","        x = self.l1(x)\n","        x = self.l2(x)\n","        return x\n","\n","    def get_weights(self):\n","        return self.l1.get_weights() + self.l2.get_weights()\n","\n","    def set_weights(self, weights):\n","        l1_weights = weights[:2]\n","        l2_weights = weights[2:]\n","        self.l1.set_weights(l1_weights)\n","        self.l2.set_weights(l2_weights)\n","\n","\n","class EncoderBlock(tf.keras.layers.Layer):\n","    def __init__(self, dModel, num_heads):\n","        super(EncoderBlock, self).__init__()\n","        self.dModel = dModel\n","        self.num_heads = num_heads\n","        self.MhA = tf.keras.layers.MultiHeadAttention(num_heads, dModel // num_heads)\n","        self.LayerNorm1 = tf.keras.layers.LayerNormalization()\n","        self.LayerNorm2 = tf.keras.layers.LayerNormalization()\n","        self.Add = tf.keras.layers.Add()\n","        self.FeedForward = FeedForward(dModel)\n","\n","    def call(self, x, *args, **kwargs):\n","        skip = x\n","        x = self.MhA(key=x, query=x, value=x)\n","        x = self.Add([x, skip])\n","        x = self.LayerNorm1(x)\n","        skip = x\n","        x = self.FeedForward(x)\n","        x = self.Add([x, skip])\n","        x = self.LayerNorm2(x)\n","        return x\n","\n","    def get_weights(self):\n","        mha_weights=self.MhA.get_weights()\n","\n","        weights= mha_weights+ self.LayerNorm1.get_weights() + \\\n","            self.LayerNorm2.get_weights() + self.FeedForward.get_weights()\n","        return weights\n","\n","    def set_weights(self, weights):\n","        mhA_weights = weights[:8]\n","        lNorm1_weights = weights[8:10]\n","        lNorm2_weights = weights[10:12]\n","        ff_weights = weights[12:]\n","        self.MhA.set_weights(mhA_weights)\n","        self.LayerNorm1.set_weights(lNorm1_weights)\n","        self.LayerNorm2.set_weights(lNorm2_weights)\n","        self.FeedForward.set_weights(ff_weights)\n","\n","\n","class DecoderBlock(tf.keras.layers.Layer):\n","    def __init__(self, dModel, num_heads):\n","        super(DecoderBlock, self).__init__()\n","        self.dModel = dModel\n","        self.num_heads = num_heads\n","        self.MhA = tf.keras.layers.MultiHeadAttention(num_heads, dModel // num_heads)\n","        self.MMhA= tf.keras.layers.MultiHeadAttention(num_heads, dModel // num_heads)\n","        self.LayerNorm1 = tf.keras.layers.LayerNormalization()\n","        self.LayerNorm2 = tf.keras.layers.LayerNormalization()\n","        self.LayerNorm3 = tf.keras.layers.LayerNormalization()\n","        self.Add = tf.keras.layers.Add()\n","        self.FeedForward = FeedForward(dModel)\n","\n","    def call(self, x, encoder_out, *args, **kwargs):\n","        skip = x\n","        x = self.MMhA(query=x, value=x, key=x, use_causal_mask=True)\n","        x = self.Add([x, skip])\n","        x = self.LayerNorm1(x)\n","        skip = x\n","        x = self.MhA(query=x, key=encoder_out, value=encoder_out)\n","        x = self.Add([x, skip])\n","        x = self.LayerNorm2(x)\n","        skip = x\n","        x = self.FeedForward(x)\n","        x = self.Add([x, skip])\n","        x = self.LayerNorm3(x)\n","        return x\n","\n","    def get_weights(self):\n","        return self.MMhA.get_weights() + self.MhA.get_weights() + \\\n","               self.LayerNorm1.get_weights() + self.LayerNorm2.get_weights() + \\\n","               self.LayerNorm3.get_weights() + self.FeedForward.get_weights()\n","\n","    def set_weights(self, weights):\n","        mmhA_weights = weights[:8]\n","        mhA_weights = weights[8:16]\n","        lNorm1_weights = weights[16:18]\n","        lNorm2_weights = weights[18:20]\n","        lNorm3_weights = weights[20:22]\n","        ff_weights = weights[22:]\n","        self.MMhA.set_weights(mmhA_weights)\n","        self.MhA.set_weights(mhA_weights)\n","        self.LayerNorm1.set_weights(lNorm1_weights)\n","        self.LayerNorm2.set_weights(lNorm2_weights)\n","        self.LayerNorm3.set_weights(lNorm3_weights)\n","        self.FeedForward.set_weights(ff_weights)\n","\n","\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_blocks, vocab_size, dModel, num_heads):\n","        super(Decoder, self).__init__()\n","        self.num_blocks = num_blocks\n","        self.blocks = [DecoderBlock(dModel, num_heads) for _ in range(num_blocks)]\n","        self.linear= tf.keras.layers.Dense(vocab_size,activation='softmax')\n","\n","    def call(self, x, encoder_out ,*args, **kwargs):\n","        for block in self.blocks:\n","            x = block(x, encoder_out)\n","        x = self.linear(x)\n","        return x\n","\n","    def get_weights(self):\n","        weights = []\n","        for block in self.blocks:\n","            weights.extend(block.get_weights())\n","        return weights\n","\n","    def set_weights(self, weights):\n","        for block in self.blocks:\n","            block.set_weights(weights[:len(block.get_weights())])\n","            weights = weights[len(block.get_weights()):]\n","\n","\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_blocks, dModel, num_heads):\n","        super(Encoder, self).__init__()\n","        self.num_blocks = num_blocks\n","        self.blocks = [EncoderBlock(dModel, num_heads) for _ in range(num_blocks)]\n","\n","    def call(self, x, *args, **kwargs):\n","        for block in self.blocks:\n","            x = block(x)\n","        return x\n","\n","    def get_weights(self):\n","        weights = []\n","        for block in self.blocks:\n","            weights.extend(block.get_weights())\n","        return weights\n","\n","    def set_weights(self, weights):\n","        for block in self.blocks:\n","            block.set_weights(weights[:len(block.get_weights())])\n","            weights = weights[len(block.get_weights()):]\n"],"metadata":{"id":"in-1fFsSaIen","colab":{"base_uri":"https://localhost:8080/","height":279,"referenced_widgets":["837651a9d71a4c679477ef90eac0eec4","9ee1e22c88124a088fad831a2006276b","7f52807eb1ee40c6bb61c47d778eee5b","e130f74d6f2f46e6b181b95ebd7df44a","f38ef88ac3eb4213a1911a0c7a28d4b2","a55f8346fc4b4f25bb5d404762043851","19de5c56c15c40199eea12be84824752","57cb6e98995a405384db9301c96420e1","55ab170f640749f4b56a9e0ad4ef06e7","f7634c007a7247fb866d1cb7bf37a282","9288fc7d76fc4e99a064008d02d20d81","e83ab7e3d1cd44b5bbb8dd944d13bf12","a4dcde26c79b454aa18adb248e60d1ca","9581df2862e34a71bda4bf3b231a1a1c","511eeff4eab8492b92ff988eb5aad893","ea14e83007a7414187dc6c6d945e883c","fffe04be5873473d91248051b3867c2c","9e1e1c136e3d4d9f9d96400f4aadc2d9","cfb997c67b9f42cfb4b79212f612a0a3","3de498340d5d45e2babfbcf267f434db","babf9841bf33454c8a1db04c53938488","323a5a21e4804adebfd9084245a68810","2eef038216e941fda942b815efa0c498","83bfabd315fd4eb18a75a25633c1700d","e29ccce10da44bdda1e544a3b5bb5870","da0ff6c85784410e837f584937ac3b8b","9056a4c17fc041608388d6a69c35baeb","84c698bb25aa4f0fbc8c0884889cafaf","e7b4cc262446446a87b32da72db9e3d3","0bbe8b345e854d0ba74336a8bb40c618","489afd87b3384912832b4f8f9d1c70e6","16ad2021e78a4eb1ba4983797e7ceb70","8458a041694d4a6cacb79a234d44444b"]},"executionInfo":{"status":"ok","timestamp":1716368675758,"user_tz":-180,"elapsed":16363,"user":{"displayName":"Simon Darius","userId":"16757888548480018100"}},"outputId":"b4ec3bc3-048f-46b9-e3ea-75c4e0dbafa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"837651a9d71a4c679477ef90eac0eec4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83ab7e3d1cd44b5bbb8dd944d13bf12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eef038216e941fda942b815efa0c498"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ff-P7cxNBzyW"},"outputs":[],"source":["\n","class Transformer(tf.keras.Model):\n","    def __init__(self, embedding_layer, encoder, decoder, optimizer):\n","        super(Transformer, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.embedding_layer = embedding_layer\n","        self.optimizer = optimizer\n","\n","    def save(self, filepath):\n","        weights = self.get_weights()\n","        with open(filepath, 'wb') as f:\n","            pickle.dump(weights, f)\n","\n","    def load(self, filepath):\n","        with open(filepath, 'rb') as f:\n","            weights = pickle.load(f)\n","        self.set_weights(weights)\n","\n","    def get_weights(self):\n","        encoder_weights = self.encoder.get_weights()\n","        decoder_weights = self.decoder.get_weights()\n","        embedding_weights = self.embedding_layer.get_weights()\n","        return encoder_weights, decoder_weights, embedding_weights\n","\n","    def set_weights(self, weights):\n","        encoder_weights, decoder_weights, embedding_weights = weights\n","        self.encoder.set_weights(encoder_weights)\n","        self.decoder.set_weights(decoder_weights)\n","        self.embedding_layer.set_weights(embedding_weights)\n","    def compute_loss(self, targets, predictions):\n","        targets_flat = tf.reshape(targets, [-1])\n","        predictions_flat = tf.reshape(predictions, [-1, tf.shape(predictions)[-1]])\n","        targets_one_hot = tf.one_hot(targets_flat, depth=predictions_flat.shape[-1])\n","        print(f\"prediction shape before loss {predictions_flat.shape} , target shape before loss {targets_one_hot.shape}\")\n","        loss = tf.keras.losses.categorical_crossentropy(targets_one_hot, predictions_flat, from_logits=True)\n","        loss = tf.reduce_mean(loss)\n","        return loss\n","\n","    def train_step(self, eng_tokens, fr_tokens):\n","        eng_batch = self.embedding_layer(eng_tokens)\n","        fr_batch = self.embedding_layer(fr_tokens)\n","\n","        with tf.GradientTape() as tape:\n","            encoder_out = self.encoder(eng_batch)\n","            decoder_out = self.decoder(fr_batch, encoder_out)\n","            loss = self.compute_loss(fr_tokens[:, 1:], decoder_out[:, :-1])  # Ignore <BOS> token in targets\n","\n","        gradients = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n","        self.optimizer.apply_gradients(\n","            zip(gradients, self.encoder.trainable_variables + self.decoder.trainable_variables))\n","\n","        return loss\n","\n","    def fit(self, train_df, test_df, num_epochs, batch_size):\n","        train_english_sentences = train_df[\"English\"].values\n","        train_french_sentences = train_df[\"French\"].values\n","\n","        for epoch in range(num_epochs):\n","            epoch_loss = 0\n","            num_batches = len(train_english_sentences) // batch_size\n","            for i in range(1, int(train_english_sentences.shape[0] / batch_size)):\n","                eng = train_english_sentences[batch_size * i:batch_size * (i + 1)]\n","                fr = train_french_sentences[batch_size * i:batch_size * (i + 1)]\n","\n","                eng_token = np.array(tokenizer(list(eng), padding=True)['input_ids'])\n","                fr_token = np.array(tokenizer(list(fr), padding=True)['input_ids'])\n","                fr_token = np.insert(fr_token, 0, tokenizer.bos_token_id, axis=1)\n","\n","                loss = self.train_step(eng_token, fr_token)\n","                epoch_loss += loss\n","\n","                print(f\"Batch {i}/{num_batches} Loss: {loss:.4f} Epoch {epoch + 1}\")\n","\n","            model.save(f'weights_run2_{epoch}.pkl')\n","            print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / num_batches:.4f}\")\n","\n","            test_loss = self.evaluate(test_df, batch_size)\n","            print(f\"Validation Loss: {test_loss:.4f}\")\n","\n","    def evaluate(self, test_df, batch_size):\n","        test_english_sentences = test_df[\"English\"].values\n","        test_french_sentences = test_df[\"French\"].values\n","        total_loss = 0\n","\n","        num_batches = len(test_english_sentences) // batch_size\n","        for i in range(1, int(test_english_sentences.shape[0] / batch_size)):\n","            eng = test_english_sentences[batch_size * i:batch_size * (i + 1)]\n","            fr = test_french_sentences[batch_size * i:batch_size * (i + 1)]\n","\n","            eng_token = np.array(tokenizer(list(eng), padding=True)['input_ids'])\n","            fr_token = np.array(tokenizer(list(fr), padding=True)['input_ids'])\n","            fr_token = np.insert(fr_token, 0, tokenizer.bos_token_id, axis=1)\n","\n","            loss = self.compute_loss(fr_token[:, 1:], self.decoder(self.embedding_layer(fr_token),\n","                                                                   self.encoder(self.embedding_layer(eng_token)))[:,\n","                                                      :-1])\n","            total_loss += loss\n","\n","        return total_loss / num_batches\n","\n","    def inference(self, input_text, max_length=50):\n","        input_tokens = np.array(tokenizer([input_text], padding=True)['input_ids'])\n","\n","        output_tokens = np.array([[tokenizer.bos_token_id]])\n","\n","        for _ in range(max_length):\n","            input_embeddings = self.embedding_layer(input_tokens)\n","            output_embeddings = self.embedding_layer(output_tokens)\n","\n","            encoder_out = self.encoder(input_embeddings)\n","\n","            decoder_out = self.decoder(output_embeddings, encoder_out)\n","\n","            last_token_logits = decoder_out[:, -1, :]\n","\n","            next_token_id = tf.argmax(last_token_logits, axis=-1)\n","\n","            output_tokens = np.concatenate([output_tokens, next_token_id[:, tf.newaxis]], axis=-1)\n","\n","            if next_token_id[0] == tokenizer.eos_token_id:\n","                print('GOT EOS TOKEN')\n","                break\n","        output_text = tokenizer.decode(output_tokens[0])\n","\n","        return output_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Axhov_q_Bmg9","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"817ae3db-7315-403d-a83f-8cf86d1375a9","executionInfo":{"status":"error","timestamp":1716367465499,"user_tz":-180,"elapsed":537174,"user":{"displayName":"Simon Darius","userId":"16757888548480018100"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["<start> patches patches patches acid tablespoon Development Development Development Developmentmustermuster Immobilien Immobilien Immobilien Immobilien Immobilien Williams Immobilien Immobilien electronically electronically Immobilien Immobilien governor governor rebelfaţafaţafaţafaţa Granite GranitefrequentPSTicketgutgutgut unabhängig unabhängig Mark nie nie Reform Reform Reform Reform Reform Reform Reform\n","prediction shape before loss (2112, 32101) , target shape before loss (2112, 32101)\n","Batch 1/2195 Loss: 10.3767 Epoch 1\n","prediction shape before loss (1408, 32101) , target shape before loss (1408, 32101)\n","Batch 2/2195 Loss: 10.3766 Epoch 1\n","prediction shape before loss (2048, 32101) , target shape before loss (2048, 32101)\n","Batch 3/2195 Loss: 10.3767 Epoch 1\n","prediction shape before loss (2176, 32101) , target shape before loss (2176, 32101)\n","Batch 4/2195 Loss: 10.3767 Epoch 1\n","prediction shape before loss (1792, 32101) , target shape before loss (1792, 32101)\n","Batch 5/2195 Loss: 10.3767 Epoch 1\n","prediction shape before loss (1472, 32101) , target shape before loss (1472, 32101)\n","Batch 6/2195 Loss: 10.3767 Epoch 1\n","prediction shape before loss (2496, 32101) , target shape before loss (2496, 32101)\n","Batch 7/2195 Loss: 10.3765 Epoch 1\n","prediction shape before loss (1600, 32101) , target shape before loss (1600, 32101)\n","Batch 8/2195 Loss: 10.3758 Epoch 1\n","prediction shape before loss (2048, 32101) , target shape before loss (2048, 32101)\n","Batch 9/2195 Loss: 10.3756 Epoch 1\n","prediction shape before loss (2240, 32101) , target shape before loss (2240, 32101)\n","Batch 10/2195 Loss: 10.3743 Epoch 1\n","prediction shape before loss (2176, 32101) , target shape before loss (2176, 32101)\n","Batch 11/2195 Loss: 10.3734 Epoch 1\n","prediction shape before loss (2176, 32101) , target shape before loss (2176, 32101)\n","Batch 12/2195 Loss: 10.3707 Epoch 1\n","prediction shape before loss (1664, 32101) , target shape before loss (1664, 32101)\n","Batch 13/2195 Loss: 10.3687 Epoch 1\n","prediction shape before loss (3200, 32101) , target shape before loss (3200, 32101)\n","Batch 14/2195 Loss: 10.3511 Epoch 1\n","prediction shape before loss (2048, 32101) , target shape before loss (2048, 32101)\n","Batch 15/2195 Loss: 10.3396 Epoch 1\n","prediction shape before loss (3776, 32101) , target shape before loss (3776, 32101)\n","Batch 16/2195 Loss: 10.2788 Epoch 1\n","prediction shape before loss (1728, 32101) , target shape before loss (1728, 32101)\n","Batch 17/2195 Loss: 10.2526 Epoch 1\n","prediction shape before loss (1792, 32101) , target shape before loss (1792, 32101)\n","Batch 18/2195 Loss: 10.1505 Epoch 1\n","prediction shape before loss (1856, 32101) , target shape before loss (1856, 32101)\n","Batch 19/2195 Loss: 9.9777 Epoch 1\n","prediction shape before loss (1664, 32101) , target shape before loss (1664, 32101)\n","Batch 20/2195 Loss: 9.9279 Epoch 1\n","prediction shape before loss (1536, 32101) , target shape before loss (1536, 32101)\n","Batch 21/2195 Loss: 9.8870 Epoch 1\n","prediction shape before loss (1856, 32101) , target shape before loss (1856, 32101)\n","Batch 22/2195 Loss: 9.8594 Epoch 1\n","prediction shape before loss (2048, 32101) , target shape before loss (2048, 32101)\n","Batch 23/2195 Loss: 9.8614 Epoch 1\n","prediction shape before loss (2240, 32101) , target shape before loss (2240, 32101)\n","Batch 24/2195 Loss: 9.7718 Epoch 1\n","prediction shape before loss (2112, 32101) , target shape before loss (2112, 32101)\n","Batch 25/2195 Loss: 9.8029 Epoch 1\n","prediction shape before loss (2112, 32101) , target shape before loss (2112, 32101)\n","Batch 26/2195 Loss: 9.8109 Epoch 1\n","prediction shape before loss (1920, 32101) , target shape before loss (1920, 32101)\n","Batch 27/2195 Loss: 9.7955 Epoch 1\n","prediction shape before loss (1792, 32101) , target shape before loss (1792, 32101)\n","Batch 28/2195 Loss: 9.8818 Epoch 1\n","prediction shape before loss (1856, 32101) , target shape before loss (1856, 32101)\n","Batch 29/2195 Loss: 9.8439 Epoch 1\n","prediction shape before loss (1600, 32101) , target shape before loss (1600, 32101)\n","Batch 30/2195 Loss: 9.9055 Epoch 1\n","prediction shape before loss (2304, 32101) , target shape before loss (2304, 32101)\n","Batch 31/2195 Loss: 9.7670 Epoch 1\n","prediction shape before loss (2048, 32101) , target shape before loss (2048, 32101)\n","Batch 32/2195 Loss: 9.8211 Epoch 1\n","prediction shape before loss (2304, 32101) , target shape before loss (2304, 32101)\n","Batch 33/2195 Loss: 9.7483 Epoch 1\n","prediction shape before loss (1856, 32101) , target shape before loss (1856, 32101)\n","Batch 34/2195 Loss: 9.8374 Epoch 1\n","prediction shape before loss (1792, 32101) , target shape before loss (1792, 32101)\n","Batch 35/2195 Loss: 9.8846 Epoch 1\n","prediction shape before loss (2368, 32101) , target shape before loss (2368, 32101)\n","Batch 36/2195 Loss: 9.7383 Epoch 1\n","prediction shape before loss (1856, 32101) , target shape before loss (1856, 32101)\n","Batch 37/2195 Loss: 9.8331 Epoch 1\n","prediction shape before loss (1984, 32101) , target shape before loss (1984, 32101)\n","Batch 38/2195 Loss: 9.8254 Epoch 1\n","prediction shape before loss (2240, 32101) , target shape before loss (2240, 32101)\n","Batch 39/2195 Loss: 9.7736 Epoch 1\n","prediction shape before loss (1728, 32101) , target shape before loss (1728, 32101)\n","Batch 40/2195 Loss: 9.8872 Epoch 1\n","prediction shape before loss (1472, 32101) , target shape before loss (1472, 32101)\n","Batch 41/2195 Loss: 9.9345 Epoch 1\n","prediction shape before loss (1920, 32101) , target shape before loss (1920, 32101)\n","Batch 42/2195 Loss: 9.8679 Epoch 1\n","prediction shape before loss (1664, 32101) , target shape before loss (1664, 32101)\n","Batch 43/2195 Loss: 9.8900 Epoch 1\n","prediction shape before loss (1920, 32101) , target shape before loss (1920, 32101)\n","Batch 44/2195 Loss: 9.8387 Epoch 1\n","prediction shape before loss (2752, 32101) , target shape before loss (2752, 32101)\n","Batch 45/2195 Loss: 9.7227 Epoch 1\n","prediction shape before loss (2240, 32101) , target shape before loss (2240, 32101)\n","Batch 46/2195 Loss: 9.7536 Epoch 1\n","prediction shape before loss (1536, 32101) , target shape before loss (1536, 32101)\n","Batch 47/2195 Loss: 9.9230 Epoch 1\n","prediction shape before loss (2112, 32101) , target shape before loss (2112, 32101)\n","Batch 48/2195 Loss: 9.7863 Epoch 1\n","prediction shape before loss (2496, 32101) , target shape before loss (2496, 32101)\n","Batch 49/2195 Loss: 9.7478 Epoch 1\n","prediction shape before loss (1536, 32101) , target shape before loss (1536, 32101)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-4f9db8064c4a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello! How are you?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-28b604a0f816>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_df, test_df, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mfr_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-28b604a0f816>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, eng_tokens, fr_tokens)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         self.optimizer.apply_gradients(\n\u001b[0m\u001b[1;32m     50\u001b[0m             zip(gradients, self.encoder.trainable_variables + self.decoder.trainable_variables))\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;31m# Apply gradient updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# Run udpate step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             self._backend_update_step(\n\u001b[0m\u001b[1;32m    406\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         ]\n\u001b[0;32m--> 119\u001b[0;31m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_tf_update_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribute_lib.get_replica_context().merge_call(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3003\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   3004\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m       return self._replica_ctx_update(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4073\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4075\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4079\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_velocities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_variable_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta_2_power\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta_1_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         self.assign_add(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'debugging.is_traceback_filtering_enabled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \"\"\"Check whether traceback filtering is currently enabled.\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["df = pd.read_csv(\"eng_fr.csv\", header=None, names=[\"English\", \"French\"])\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","embedding_layer = TransformerEmbedding(tokenizer.vocab_size + 1, 128, 60)\n","encoder = Encoder(dModel=128, num_blocks=6, num_heads=4)\n","decoder= Decoder(vocab_size=tokenizer.vocab_size + 1, dModel= 128, num_heads=4, num_blocks=3)\n","model = Transformer(embedding_layer, encoder, decoder,optimizer=tf.keras.optimizers.Adam(learning_rate=0.005))\n","\n","#test...\n","\n","response=model.inference(\"Hello! How are you?\")\n","print(response)\n","\n","\n","model.fit(train_df, test_df, 3, )"]},{"cell_type":"code","source":["#Alternative Transformer class for question answering tasks\n","\n","class Transformer(tf.keras.Model):\n","    def __init__(self, embedding_layer, encoder, decoder, optimizer):\n","        super(Transformer, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.embedding_layer = embedding_layer\n","        self.optimizer = optimizer\n","\n","    def save(self, filepath):\n","        weights = self.get_weights()\n","        with open(filepath, 'wb') as f:\n","            pickle.dump(weights, f)\n","\n","    def load(self, filepath):\n","        with open(filepath, 'rb') as f:\n","            weights = pickle.load(f)\n","        self.set_weights(weights)\n","\n","    def get_weights(self):\n","        encoder_weights = self.encoder.get_weights()\n","        decoder_weights = self.decoder.get_weights()\n","        embedding_weights = self.embedding_layer.get_weights()\n","        return encoder_weights, decoder_weights, embedding_weights\n","\n","    def set_weights(self, weights):\n","        encoder_weights, decoder_weights, embedding_weights = weights\n","        self.encoder.set_weights(encoder_weights)\n","        self.decoder.set_weights(decoder_weights)\n","        self.embedding_layer.set_weights(embedding_weights)\n","\n","    def compute_loss(self, targets, predictions):\n","\n","\n","        max_length = max(tf.shape(targets)[1], tf.shape(predictions)[1])\n","        pad_targets = tf.pad(targets, [[0, 0], [0, max_length - tf.shape(targets)[1]]])\n","        pad_predictions = tf.pad(predictions, [[0, 0], [0, max_length - tf.shape(predictions)[1]], [0, 0]])\n","\n","\n","\n","        targets_flat = tf.reshape(pad_targets, [-1])\n","        predictions_flat = tf.reshape(pad_predictions, [-1, tf.shape(pad_predictions)[-1]])\n","        targets_one_hot = tf.one_hot(targets_flat, depth=predictions_flat.shape[-1])\n","        loss = tf.keras.losses.categorical_crossentropy(targets_one_hot, predictions_flat, from_logits=True)\n","        loss = tf.reduce_mean(loss)\n","        return loss\n","\n","\n","    def train_step(self, context_tokens, question_tokens, answer_tokens):\n","        context_batch = self.embedding_layer(context_tokens)\n","        question_batch = self.embedding_layer(question_tokens)\n","\n","        with tf.GradientTape() as tape:\n","            encoder_out = self.encoder(context_batch)\n","            decoder_out = self.decoder(question_batch, encoder_out)\n","\n","            loss = self.compute_loss(answer_tokens[:, 1:], decoder_out[:, :-1])  # Ignore <BOS> token in targets\n","\n","        gradients = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n","        self.optimizer.apply_gradients(\n","            zip(gradients, self.encoder.trainable_variables + self.decoder.trainable_variables))\n","\n","        return loss\n","\n","    def fit(self, train_data, test_data, num_epochs, batch_size):\n","        num_batches = len(train_data['context']) // batch_size\n","        for epoch in range(num_epochs):\n","            epoch_loss = 0\n","            for i in range(num_batches):\n","                context_batch = train_data['context'][i * batch_size:(i + 1) * batch_size]\n","                question_batch = train_data['question'][i * batch_size:(i + 1) * batch_size]\n","                answer_batch = train_data['answer'][i * batch_size:(i + 1) * batch_size]\n","\n","                context_tokens = np.array(tokenizer(list(context_batch), padding=True)['input_ids'])\n","                question_tokens = np.array(tokenizer(list(question_batch), padding=True)['input_ids'])\n","                answer_tokens = np.array(tokenizer(list(answer_batch), padding=True)['input_ids'])\n","                answer_tokens = np.insert(answer_tokens, 0, tokenizer.bos_token_id, axis=1)\n","\n","                loss = self.train_step(context_tokens, question_tokens, answer_tokens)\n","                epoch_loss += loss\n","\n","                print(f\"Batch {i + 1}/{num_batches} Loss: {loss:.4f} Epoch {epoch + 1}\")\n","\n","            avg_epoch_loss = epoch_loss / num_batches if num_batches > 0 else epoch_loss\n","            self.save(f'weights_run2_{epoch}.pkl')\n","            print(f\"Epoch {epoch + 1}, Loss: {avg_epoch_loss:.4f}\")\n","\n","            test_loss = self.evaluate(test_data, batch_size)\n","            print(f\"Validation Loss: {test_loss:.4f}\")\n","\n","    def evaluate(self, test_data, batch_size):\n","        total_loss = 0\n","        num_batches = len(test_data) // batch_size\n","        for i in range(num_batches):\n","            context_batch = test_data[i * batch_size:(i + 1) * batch_size]['context']\n","            question_batch = test_data[i * batch_size:(i + 1) * batch_size]['question']\n","            answer_batch = test_data[i * batch_size:(i + 1) * batch_size]['answer']\n","\n","            context_tokens = np.array(tokenizer(list(context_batch), padding=True)['input_ids'])\n","            question_tokens = np.array(tokenizer(list(question_batch), padding=True)['input_ids'])\n","            answer_tokens = np.array(tokenizer(list(answer_batch), padding=True)['input_ids'])\n","            answer_tokens = np.insert(answer_tokens, 0, tokenizer.bos_token_id, axis=1)\n","\n","            loss = self.compute_loss(answer_tokens[:, 1:], self.decoder(self.embedding_layer(answer_tokens),\n","                                                                       self.encoder(self.embedding_layer(context_tokens)))[:, :-1])\n","            total_loss += loss\n","        if(num_batches==0):\n","          num_batches=1\n","        return total_loss / 1\n","\n","    def inference(self, context_text, question_text, max_length=50):\n","        context_tokens = np.array(tokenizer([context_text], padding=True)['input_ids'])\n","        question_tokens = np.array(tokenizer([question_text], padding=True)['input_ids'])\n","\n","        output_tokens = np.array([[tokenizer.bos_token_id]])\n","\n","        for _ in range(max_length):\n","            context_embeddings = self.embedding_layer(context_tokens)\n","            question_embeddings = self.embedding_layer(question_tokens)\n","            output_embeddings = self.embedding_layer(output_tokens)\n","\n","            encoder_out = self.encoder(context_embeddings)\n","\n","            decoder_out = self.decoder(output_embeddings, encoder_out)\n","\n","            last_token_logits = decoder_out[:, -1, :]\n","\n","            next_token_id = tf.argmax(last_token_logits, axis=-1)\n","\n","            output_tokens = np.concatenate([output_tokens, next_token_id[:, tf.newaxis]], axis=-1)\n","\n","            if next_token_id[0] == tokenizer.eos_token_id:\n","                print('GOT EOS TOKEN')\n","                break\n","\n","        output_text = tokenizer.decode(output_tokens[0])\n","        return output_text"],"metadata":{"id":"nuM4W32rU1Xx"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyM0xANMjLjLWtBtgrRJsSHo"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"837651a9d71a4c679477ef90eac0eec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ee1e22c88124a088fad831a2006276b","IPY_MODEL_7f52807eb1ee40c6bb61c47d778eee5b","IPY_MODEL_e130f74d6f2f46e6b181b95ebd7df44a"],"layout":"IPY_MODEL_f38ef88ac3eb4213a1911a0c7a28d4b2"}},"9ee1e22c88124a088fad831a2006276b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a55f8346fc4b4f25bb5d404762043851","placeholder":"​","style":"IPY_MODEL_19de5c56c15c40199eea12be84824752","value":"config.json: 100%"}},"7f52807eb1ee40c6bb61c47d778eee5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57cb6e98995a405384db9301c96420e1","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55ab170f640749f4b56a9e0ad4ef06e7","value":1208}},"e130f74d6f2f46e6b181b95ebd7df44a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7634c007a7247fb866d1cb7bf37a282","placeholder":"​","style":"IPY_MODEL_9288fc7d76fc4e99a064008d02d20d81","value":" 1.21k/1.21k [00:00&lt;00:00, 12.2kB/s]"}},"f38ef88ac3eb4213a1911a0c7a28d4b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a55f8346fc4b4f25bb5d404762043851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19de5c56c15c40199eea12be84824752":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57cb6e98995a405384db9301c96420e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55ab170f640749f4b56a9e0ad4ef06e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7634c007a7247fb866d1cb7bf37a282":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9288fc7d76fc4e99a064008d02d20d81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e83ab7e3d1cd44b5bbb8dd944d13bf12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4dcde26c79b454aa18adb248e60d1ca","IPY_MODEL_9581df2862e34a71bda4bf3b231a1a1c","IPY_MODEL_511eeff4eab8492b92ff988eb5aad893"],"layout":"IPY_MODEL_ea14e83007a7414187dc6c6d945e883c"}},"a4dcde26c79b454aa18adb248e60d1ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fffe04be5873473d91248051b3867c2c","placeholder":"​","style":"IPY_MODEL_9e1e1c136e3d4d9f9d96400f4aadc2d9","value":"spiece.model: 100%"}},"9581df2862e34a71bda4bf3b231a1a1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfb997c67b9f42cfb4b79212f612a0a3","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3de498340d5d45e2babfbcf267f434db","value":791656}},"511eeff4eab8492b92ff988eb5aad893":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_babf9841bf33454c8a1db04c53938488","placeholder":"​","style":"IPY_MODEL_323a5a21e4804adebfd9084245a68810","value":" 792k/792k [00:00&lt;00:00, 4.66MB/s]"}},"ea14e83007a7414187dc6c6d945e883c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fffe04be5873473d91248051b3867c2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e1e1c136e3d4d9f9d96400f4aadc2d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfb997c67b9f42cfb4b79212f612a0a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3de498340d5d45e2babfbcf267f434db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"babf9841bf33454c8a1db04c53938488":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"323a5a21e4804adebfd9084245a68810":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2eef038216e941fda942b815efa0c498":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83bfabd315fd4eb18a75a25633c1700d","IPY_MODEL_e29ccce10da44bdda1e544a3b5bb5870","IPY_MODEL_da0ff6c85784410e837f584937ac3b8b"],"layout":"IPY_MODEL_9056a4c17fc041608388d6a69c35baeb"}},"83bfabd315fd4eb18a75a25633c1700d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84c698bb25aa4f0fbc8c0884889cafaf","placeholder":"​","style":"IPY_MODEL_e7b4cc262446446a87b32da72db9e3d3","value":"tokenizer.json: 100%"}},"e29ccce10da44bdda1e544a3b5bb5870":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bbe8b345e854d0ba74336a8bb40c618","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_489afd87b3384912832b4f8f9d1c70e6","value":1389353}},"da0ff6c85784410e837f584937ac3b8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16ad2021e78a4eb1ba4983797e7ceb70","placeholder":"​","style":"IPY_MODEL_8458a041694d4a6cacb79a234d44444b","value":" 1.39M/1.39M [00:00&lt;00:00, 5.93MB/s]"}},"9056a4c17fc041608388d6a69c35baeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c698bb25aa4f0fbc8c0884889cafaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7b4cc262446446a87b32da72db9e3d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bbe8b345e854d0ba74336a8bb40c618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"489afd87b3384912832b4f8f9d1c70e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16ad2021e78a4eb1ba4983797e7ceb70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8458a041694d4a6cacb79a234d44444b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}